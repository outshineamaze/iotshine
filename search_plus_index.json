{"./":{"url":"./","title":"简介","keywords":"","body":"项目地址 功能简介： 硬件接入功能 数字型传感器接入 坐标新设备接入 图像设备接入 视频设备接入 布尔型设备接入 自定义设备接入（最后实现测试使用） 控制台中心功能 用户注册（重写用户注册登陆模块） 用户添加删除硬件设备 用户管理数据节点（手动添加删除等） 技术框架简介： 第一层： 用户端：用户端主要为网页平台和微信平台（待认证），同时也开发了api接口用于以后的app开发接入。 第二层： 网关代理： 在控制台系统中使用nginx作为反向代理挂载django程序。 在硬件设备上，使用树莓派之类具有socket 编程发送数据的单片机设备作为硬件设备的网关，将收取的数据通过http协议发送到tornado异步服务器， 第三层： Django控制台就是直接和用户打交道的，用户与系统和硬件设备的控制交互全部基于django的物联网设备控制台前端管理系统。 Tornado在系统主要负责处理硬件上传的数据，由于其本身是异步的服务器，所以相等的硬件下可以同时挂载更多多的设备，在系统的有着相当重要的地位。 第四层： 底层使用的是mysql数据库，同时与mysql同时搭配的redis内存数据库一起使用，其中mysql实现数据的持久化储存，redis实现临时数据的缓存，主要使用的场合就是实时监控或者控制数据储存。 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"2.硬件负载服务器开始.html":{"url":"2.硬件负载服务器开始.html","title":"硬件负载服务器开始","keywords":"","body":"首先介绍一下物联网系统的挂载硬件服务器开发 这次我们的服务器是自己开发，从socket 模块一直到顶层的应用模块，自己实现了普通的tcp 和http服务器。 Python socket 简介： 这是一个很简单的Python实现的socket服务器的代码： #!/usr/bin/python # -*- coding: utf-8 -*- import socket import sys from thread import * HOST = '' PORT = 9000 s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) print 'Socket created' #Bind socket to local host and port try: s.bind((HOST,PORT)) except socket.error,msg: print 'Bind failed. Error code: %s, Message: %s' sys.exit() print 'Socket bind complete' #start listening on socket s.listen(10) print 'Socket now listening' #Function for handling connections. This will be used to create threads def clientthread(conn): #sending message to connected client conn.send('Welecome to the server.Type something and hit enter\\n') #define loop so that function do not terminate and thread do not end. while True: #receiving from client data = conn.recv(1024) file = open(\"/sys/class/thermal/thermal_zone0/temp\") temp = float(file.read()) / 1000 file.close() reply = str(temp) print reply if not data: break conn.sendall(reply) conn.close() while 1: conn,addr = s.accept() print 'Connected with %s:%s'%(addr[0],str(addr[1])) start_new_thread(clientthread,(conn,)) s.close() 当然了我们的服务器要是用这个的话是无法处理太多连接的所以我们需要在我们的服务器上用到 非阻塞，io复用等概念， 我们自制服务器是一个异步非阻塞的服务器， 那么来介绍几个概念： 阻塞： 阻塞是个什么概念呢？比如某个时候你在等快递，但是你不知道快递什么时候过来，而且你没有别的事可以干（或者说接下来的事要等快递来了才能做）；那么你可以去睡觉了，因为你知道快递把货送来时一定会给你打个电话（假定一定能叫醒你）。 非阻塞忙轮询： 接着上面等快递的例子，如果用忙轮询的方法，那么你需要知道快递员的手机号，然后每分钟给他挂个电话：“你到了没？”我们后面要介绍的select 复用模型就是用的这种概念。 为了解释阻塞是如何进行的，我们来讨论缓冲区 假设有一个管道，进程A为管道的写入方，B为管道的读出方。 假设一开始内核缓冲区是空的，B作为读出方，被阻塞着。然后首先A往管道写入，这时候内核缓冲区由空的状态变到非空状态，内核就会产生一个事件告诉B该醒来了，这个事件姑且称之为“缓冲区非空”。 但是“缓冲区非空”事件通知B后，B却还没有读出数据；且内核许诺了不能把写入管道中的数据丢掉这个时候，A写入的数据会滞留在内核缓冲区中，如果内核也缓冲区满了，B仍未开始读数据，最终内核缓冲区会被填满，这个时候会产生一个I/O事件，告诉进程A，你该等等（阻塞）了，我们把这个事件定义为“缓冲区满”。 假设后来B终于开始读数据了，于是内核的缓冲区空了出来，这时候内核会告诉A，内核缓冲区有空位了，你可以从长眠中醒来了，继续写数据了，我们把这个事件叫做“缓冲区非满” 也许事件Y1已经通知了A，但是A也没有数据写入了，而B继续读出数据，知道内核缓冲区空了。这个时候内核就告诉B，你需要阻塞了！，我们把这个时间定为“缓冲区空”。 这四个情形涵盖了四个I/O事件，缓冲区满，缓冲区空，缓冲区非空，缓冲区非满。这四个I/O事件是进行阻塞同步的根本。（如果不能理解“同步”是什么概念，请学习操作系统的锁，信号量，条件变量等任务同步方面的相关知识）。 然后我们来说说阻塞I/O的缺点 （本文最开始贴的socket代码就是阻塞的io）。但是阻塞I/O模式下，一个线程只能处理一个流的I/O事件。如果想要同时处理多个流，要么多进程(fork)，要么多线程(pthread_create)，很不幸这两种方法效率都不高。 再来考虑非阻塞忙轮询的I/O方式 我们发现我们可以同时处理多个流了（把一个流从阻塞模式切换到非阻塞模式再此不予讨论）： while true { for i in stream[]; { if i has data read until unavailable } } 我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了，但这样的做法显然不好，因为如果所有的流都没有数据，那么只会白白浪费CPU。这里要补充一点，阻塞模式下，内核对于I/O事件的处理是阻塞或者唤醒，而非阻塞模式下则把I/O事件交给其他对象（后文介绍的 select 以及 epoll）处理甚至直接忽略。 这里要简单介绍一下网络编程中的io复用： select，poll，epoll都是IO多路复用的机制。所谓I/O多路复用机制，就是说通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 我们将在下面详细讨论关于io复用的内容 为了避免CPU空转，可以引进了一个代理（一开始有一位叫做select的代理，后来又有一位叫做poll的代理，不过两者的本质是一样的）。这个代理比较厉害，可以同时观察许多流的I/O事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流（于是我们可以把“忙”字去掉了）。代码长这样： while true { select(streams[]) for i in streams[] { if i has data read until unavailable } } 于是，如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。 但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，每一次无差别轮询时间就越长。 前面的select和poll都是要从头到尾遍历所有的fd（文件描述符），每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大，同时select支持的文件描述符数量太小了，默认是1024，而poll在支持文件描述符上面没有限制。 现在可以来介绍一下我们自制服务器使用的epoll模型啦， epoll 可以理解为event poll，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了O(k)，k为产生I/O事件的流的个数，也有认为O(1)的[原文为O(1)，但实际上O(k)更为准确]） epoll的主要模型流程： epoll_create 创建一个epoll对象，一般epollfd = epoll_create() epoll_ctl （epoll_add/epoll_del的合体），往epoll对象中增加/删除某一个流的某一个事件。比如 epoll_ctl(epollfd, EPOLL_CTL_ADD, socket, EPOLLIN);//有缓冲区内有数据时epoll_wait返回，epoll_ctl(epollfd, EPOLL_CTL_DEL, socket, EPOLLOUT);缓冲区可写入时epoll_wait返回 epoll_wait(epollfd,...)等待直到注册的事件发生 epoll和select，poll最大的区别是它是它有一个就绪链表来储存就绪的fd，当设备就绪，唤醒等待队列上的等待者时，就会调用一个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）select和poll在“唤醒”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表有没有就绪的fd就好了，这样极大的节省了cpu的时间。 具体的epoll 模型在我们的项目中如何使用我们在下一篇文章里面详细了解 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"3.io复用的应用.html":{"url":"3.io复用的应用.html","title":"IO复用","keywords":"","body":"上一节简单地介绍了关于io服用 epoll和select 的模型概念 这一篇文章主要来讲讲如何在项目中使用这种模型 下面是一个最基本的epoll 模型的使用的代码: #!/usr/bin/python # -*- coding: utf-8 -*- import socket import select import Queue server = socket.socket(socket.AF_INET,socket.SOCK_STREAM) server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) server_address = (\"127.0.0.1\", 8888) timeout = 10 server.bind(server_address) server.listen(5) print 'server is running listen ip ',server_address server = socket.socket(socket.AF_INET,socket.SOCK_STREAM) server.setblocking(0) epoll= select.epoll() epoll.register(server,fileno(),select.EPOLLIN) message_queues ={} fd_to_socket = {server.fileno():server} while True: print \"waiting for connecting .........\" events = epoll.poll(timeout ) if not events: print 'there is no events for connecting...' continue for fd,event in events: socket = fd_to_socket[fd] if socket & select.EPOLLIN: if socket == server: connection ,address = server.accept() print 'new connection ',address connection.setblocking(0) epoll.register(connection.fileno(),select.EPOLLIN) fd_to_socket[connection.fileno()]= connection message_queues[connection] =Queue.Queue() else: data = socket.recv(1024) if data : print 'recv data ',data,'client :' ,socket.getpeername() message_queues[socket].put(data) epoll.modify(fd,select.EPOLLOUT) elif event &select.EPOLLOUT: try : msg = message_queues(socket).get_nowait() except Queue.Empty: print 'quere Empty',socket.getpeername() epoll.moddify(fd,select.EPOLLIN) else: print 'send data:',data,'>>>client :',socket.getpeername() socket.sendall(msg) elif event &select.EPOLLHUB: epoll.unregister(fd) fd_to_socket[fd].close() del fd_to_socket[fd] epoll.unregister(server.fileno()) epoll.close() server.close() 下面这个是一个基于select 模型聊天服务器的示例代码, 主要的是使用select模型来监控多个socket文件描述符: #!/usr/bin/python #coding:utf-8 import sys import socket import select import time class chatserver(object): def __init__(self, host,port,timeout =10,request_size=10): self.clients = 0 self.clientmap={} self.outputs = [] self.server.setsockopt( socket.SOL_SOCKET, socket.SO_REUSEADDR, 1 ) self.server.bind((host,port)) self.server.listen(request_size) def run(self): status = '200 OK' response ='HTTP1.1/ {status}\\r\\n'.format(status = status) response_headers = 'Content-Type:text/plain' response +=response_headers response +='\\r\\n\\r\\n' head = response print '>start run server head is >>new connect from client %s'%str(addr) self.clients +=1 print \"client number is :\"+str(self.clients) self.outputs.append(client) self.clientmap[client]=addr input.append(client) else : try: data = sock.recv(1024) except socket.error,e: print \"Error receiving data: %s\"%e data=False if data: result =response+ 'this is response from server' print \"this is response:\\n\" print result sock.sendall(result) print '\\nsuccess return response\\n' if sock in self.outputs:self.outputs.remove(sock) print '\\nclose connection' input.remove(sock) sock.close() else: if sock in self.outputs:self.outputs.remove(sock) print 'no message from client' input.remove(sock) sock.close() self.server.close() if __name__ == '__main__': server = chatserver('',8888) server.run() 上面用很简短的代码就实现了一个在Windows可以运行的聊天服务器了,同样的如果在Linux上面运行的话完全可以使用epoll来代替select. 下面是一个很简介的客户端程序,虽然就几行代码但是完全可以使用进行基本的链接测试,在以后的项目中也会经常被用到 #!/usr/bin/python import socket # create an INET, STREAMing socket s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # now connect to the web server on port 80 - the normal http port s.connect((\"127.0.0.1\", 8888)) s.sendall('GET HTTP1.x/ ') clientsocket, address = s.accept() result = clientsocket.recv(1024) print result s.close 好了,贴了这么多的代码,我们来说说我们的平台是如何使用这个epoll和select io复用模型的: 首先来贴一下我们的 loop.py 文件的代码,这个文件主要有两个类,分别把select和epoll模型封装好, 因为篇幅的问题我就简单的把核心的代码贴出来,并且把注释也删除掉,当然后面这部分的代码也会继续完善的,具体的查考github上面的源代码. #!/usr/bin/python #coding:utf-8 import sys import os import select import threading import time import select class SelectLoop(object): def __init__(self,server,timeout,callback): self.server= server self.timeout = timeout self.callback = callback def start(self): print 'start main select loop' input = [self.server] output = [] running = True while running: try : readble,writeable,exception = select.select(input,output,[]) except select.error,e: break for sock in readble: if sock is self.server: client ,addr = self.server.accept() client.setblocking(0) print '>>>new connect from client %s'%str(addr) input.append(client) else : try: data = sock.recv(1024) except socket.error,e: print \">>>>>>>Error receiving data: %s\"%e data=False if data: print \">>>>>>>>this is response\" result = self.callback(data) print result sock.sendall(result) print '>>>>>>>>success return response' input.remove(sock) sock.close() else: print '>>>>>>no message from client' input.remove(sock) sock.close() self.server.close() class EPollLoop(object): def __init__(self,server,timeout,callback): self.callback= callback self.timeout = timeout self.server = server self.server.setblocking(0) self.epoll= select.epoll() self.epoll.register(self.server.fileno(),select.EPOLLIN) self.fd_to_socket = {self.server.fileno():self.server} def start(self): while True: print \"waiting for connecting .........\" events = self.epoll.poll(self.timeout) if not events: print 'there is no events for connecting...' continue for fd,event in events: socket = self.fd_to_socket[fd] print 'activate client socket' if socket and select.EPOLLIN: if socket == self.server: connection ,address = self.server.accept() print 'new connection ',address connection.setblocking(0) self.epoll.register(connection.fileno(),select.EPOLLIN) self.fd_to_socket[connection.fileno()]= connection else: try: data = socket.recv(1024) except: data= False if data : print 'recv data client :' ,socket.getpeername() result = self.callback(data) socket.sendall(result) print 'send data:',data,'>>>client :',socket.getpeername() self.epoll.unregister(fd) self.fd_to_socket[fd].close() del self.fd_to_socket[fd] else: print 'close client connection ',socket.getpeername() self.epoll.unregister(fd) self.fd_to_socket[fd].close() del self.fd_to_socket[fd] elif event and select.EPOLLHUB: self.epoll.unregister(fd) self.fd_to_socket[fd].close() del self.fd_to_socket[fd] self.epoll.unregister(server.fileno()) self.epoll.close() self.server.close() 我们可以看到,其实这个loop.py文件就是相当于把本篇文章最开始的那两端代码简单封装了一下而已. init() 方法主要用来初始化我们的io模型类,主要传入三个参数:server,timeout,callback . 在初始化的同时 把socket对象传入,同时也把回调函数也传入. 简单的来说loop.py里面的文件主要是把select模型和epoll 模型封装起来,然后在httpserver.py就可以自己调用了.(注;httpserver 实现tcp和http应用的主要位置) 下一篇文章来讲一下在在这个项目中是如何实现一个基本的http server,里面会用到这篇文章讲到的loop.py里面的selectloop和epollloop类 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"4.httpserver实现.html":{"url":"4.httpserver实现.html","title":"httpserver实现","keywords":"","body":"上一篇文章我们提到了关于epoll模型的封装, 在这一节我们将在httpserver中使用我们封装好的selecploop和epollloop类 在httpserver主要有两个类,第一个是httprequest类 这个类主要是封装请求内容的合集,使用的这个类将request中的信息全部封装好,然后在代码中直接传递request类的实例就好了,比如说,要获取请求的header直接就是request.header() 就可以返回头部分的信息了.话不多说,直接贴代码,这次代码同样没有人任何的注释,我会用文字详细的解释每个方法的用途. 下面是httprequest类的代码: class HttpRequest(object): def __init__(self,header,body): (self.request_method, self.request_path,self.request_version)=header.splitlines()[0].rstrip('rn').split() self.header = header self.body =body self.header_map= {} try: for lines in self.header.splitlines(): print lines if lines.find(\":\")!=-1: index = lines.index(':') (key,value) = lines[:index],lines[index:] self.header_map[key] = value except: print 'faile generator header map' pass def method(self): return self.request_method def path(self): return self.request_path def version(self): return self.request_version def body(self): return self.body def header(self): return self.header def get(self,name): if self.header_map[name]: return self.header_map[name] 我们在这个类里面把一个请求的内容全部分割好,当把这个类的实例传到其他的地方的时候,就可以直接是使用相应的方法获取我们想要的值. 下面来说说最关键的httpserver类 这个类似httpserver服务器的核心部分的代码,主要的功能是: init()初始化socket套接字,同时设置一些相关的socket的配置,比如说SEND_BUF_SIZE ,RECV_BUF_SIZE ,socket.SO_REUSEADDR等socket属性 add_app()的主要功能是把我们下一节的application传入我们的httpserver类.我们后面具体在详细讲 start_response(),finish_response(),这两个函数会被handle_one_request()调用,主要的功能就是把应用层返回到的结果组装成一个完整的http response ,然后使用sendall()函数返回给客户端 run()是httpserver的启动函数,首先判断程序运行的平台选择对应的io复用模型,其次实例epoll或者select模型,最后调用selectloop.start()方法开始监听连接主循环. 下面呢就是精简版的Httpserver的代码: class HttpServer(object): \"\"\"strt httpserver\"\"\" def __init__(self, (host,port),timeout =10,request_size=10): self.clients = 0 self.clientmap={} self.outputs = [] self.timeout = timeout SEND_BUF_SIZE = 4096 RECV_BUF_SIZE = 1024 self.server = socket.socket(socket.AF_INET,socket.SOCK_STREAM) self.server.setsockopt( socket.SOL_SOCKET, socket.SO_REUSEADDR, 1 ) self.server.bind((host,port)) self.server.listen(request_size) def add_app(self,application): self.application = application def start_response(self,status,response_headers,exc_info = None): self.header_set = (status,response_headers) def finish_response(self,result): try: status,response_headers =self.header_set print response_headers response ='HTTP/1.1 {status}\\r\\n'.format(status = status) if response_headers != []: for header in response_headers: response += '{0}: {1}\\r\\n'.format(*header) else:response+='\\r\\n' response +='\\r\\n' response += result return response except: print '*****error in finish_response****** ' return 'error in finish_response' def parse_request(self,text): try: (header,body) = text.split('\\r\\n\\r\\n') except: header =text body ='' return HttpRequest(header,body) def handle_one_request(self,data): print (''.join( '{line}'.format(line= line) for line in data.splitlines() )) result = self.application(self.parse_request(data)) print 'there is result ....' self.start_response(result[0],result[1]) return self.finish_response(result[2]) def run(self): print '>>>>>>>>>>>>>start run server 进入主循环之后,epoll或者select就不断的监听新进入的连接,它们都维持一个文件描述符的队列,所有的socket连接的文件描述符都在里面. 当一个新的连接来临时,epoll通过epoll_ctl()来注册一个文件描述符 到监听的队列,同时分配一个回调函数(主要的功能是等该连接准备就绪时把该连接加入到就绪表里面),当有一个或者多个连接准备就绪时,就开始进入业务处理遍历 ,我们将就绪表里面的对象全部遍历一遍,接受里面的数据或者是发送数据.同时把数据通过回调函数来处理, 可以看到我们这里的回调函数就是 handle_one_request() ,好了收到的数据已经到了 我们的回调函数handle_one_request() 里面了,让我们看看handle_one_request() 函数主要是做什么的: 首先handle_one_request() 将接收到的数据通过parse_request()函数来处理,返回一个httprequest类的实例,然后把这个实例传入到application里面 self.application(self.parse_request(data))这是有一个很关键的代码 到这里我们的httpserver算是完成了,接下来要把舞台交给我们应用层了,这个application有点WSGI的感觉(Web Server Gateway Interface) 下一篇将进入应用层来讨论构建应用框架的内容 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"5.应用层入口application.html":{"url":"5.应用层入口application.html","title":"应用层入口application","keywords":"","body":"这是应用层第一篇文章,后面的几篇文章也都是和应用层有关的啦 前面我们讲了关于httpserver的内容,httpserver负责网络服务器部分的内容,通过application()函数将data发送到我们的Aapplication里面,这里的application也是一个类 这篇文章主要讲的app.py这个源代码里面的内容. 下面是application类关键部分的代码: class Application(object): def __init__(self,handlers): self.add_handler(handlers) def __call__(self,req): self.Request = Request = req requestrouter = RequestRouter(self.handlers,self.Request) return requestrouter.execute() def add_handler(self,host_handler): self.handlers =[] for spec in host_handler: if isinstance(spec, (tuple)): print spec spec = URLSpec(*spec) self.handlers.append(spec) print self.handlers if spec.name: if spec.name in self.named_handlers: print \"Multiple handlers named %s; replacing previous value\"%spec.name self.named_handlers[spec.name]= spec def get_host_handlers(self): matches= [] for pattern ,handlers in self.handlers: matches.extend(handlers) return matches or None 这个application类是应用层的核心部分,首先解释一下结果函数的作用: init() 调用add_handler()函数,而这个函数的作用就是用来注册 路由-处理方法 call()这里重写了Python类里面的call函数,在实例化类后,可以直接调用把类当做一个函数调用,application(request)的其实本质上调用的就是这里的call(),我们可以注意到这个call()函数其实非常重要的一个函数, 它是一个请求在应用层的开始. call()函数一开始实例了一个requestrouter的类,顾名思义,这个类就是包含了路由解析的功能的,一个请求过来,经过路由匹配,成功之后找到对应的处理类,我们定义了每一个处理的类都是继承一个基类BaseReqest()的,匹配成功后会实例对应的处理类,同时执行_excute()方法,执行这个方法的目的是因为:一个处理类用户可以定义很多种方法,而使用_execute()方法可以根据请求的method来执行对应的处理函数.整个应用层路由解析部分的内容大致就是这样的. 下面来看下前面提到的requestrouter类和baserequest的代码: class RequestRouter(object): def __init__(self,handlers,request): self.handlers =handlers self.request = request self.handler_class = None self.handler_kwargs = {} self.path_args = [] self.path_kwargs = {} print self.request.path() self.find_handler() def find_handler(self): handlers = self.handlers if not handlers: self.handlers_class = RedirectHandler #self.handler_kwargs = {} return for spec in handlers: match = spec.regex.match(self.request.path()) print self.request.path() print match if match !=None: print spec self.handler_class = spec.handler_class self.handler_kwargs = spec.kwargs if spec.regex.groups: if spec.regex.groupindex: self.path_kwargs = dict( (str(k), _unquote_or_none(v)) for (k,v) in match.groupdict().item()) else: self.path_kwargs = [_unquote_or_none(s) for s in match.groups()] return def execute(self): if self.handler_class !=None: self.handler = self.handler_class(self.request,**self.handler_kwargs) return self.handler._excute(*self.path_args,**self.path_kwargs) else: print 'app 149 ' error = HttpError('404 ','not foound you request page ') return error() class BaseRequest(object): Default_Method = [\"GET\",\"POST\", \"DELETE\",\"PUT\"] def __init__(self,request,**kwargs): super(BaseRequest, self).__init__() self.request = request self.status_code ='200 OK' self.header = [] def _excute(self,*args,**kwargs): print 'steart _execute' try: print self.request.method if self.request.method() not in self.Default_Method: error= HttpError('405 Method Not Allowed','Invalid method') return error() self.path_args = [self.decode_argument(arg) for arg in args] self.path_kwargs = dict((k, self.decode_argument(v, name=k)) for (k, v) in kwargs.items()) method = getattr(self,self.request.method().lower()) print 'get method ...........' result = method (*self.path_args,**self.path_kwargs) print 'this is result ------.' print result if result is not None: return result except Exception as e: error= HttpError('500 Internal Server Error','some error in server ') print 'Exception in handler excute' return error() def decode_argument(self, value, name=None): try: return to_unicode(value) except UnicodeDecodeError: error = HttpError('400 Bad Request', \"Invalid unicode in %s: %r\" % (name or \"url\", value[:40])) return error() def set_status_code(self,code): self.status_code = code def set_header(self,key,value): self.header.append((key,value)) def set_cookie(self,value): self.header.append(('Cookie',value)) def Response(self,result): results = (self.status_code,self.header,result) return results 看完了这个两个类的代码再来重新看一下掌心宝似的call()函数 def __call__(self,req): self.Request = Request = req requestrouter = RequestRouter(self.handlers,self.Request) return requestrouter.execute() 可以看出requestrouter类和baserequest这两个类基本都是为这个call()函数服务的. 同时也看到baserequest这个类封装了一些基本的方法,set_header,set_cookie()等,后面会根据需求进行扩展. Response()这个函数是用来返回处理结果的.也可以重新写过增加框架的灵活性.对app.py代码的介绍差不多就这样了,app.py里面里的工具类可能比较多(其实是我懒没有写多少)就不一一把代码贴出来了,那样子意义不大. 下一篇主要讲一下,我们这个平台的main.py代码,一看就知道是干嘛用的啦,这个当然使我们启动的整个平台的入口程序 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"6.服务器入口.html":{"url":"6.服务器入口.html","title":"服务器入口","keywords":"","body":"前面介绍了application类和路由解析方面的内容 这篇文章主要介绍的是我们的服务器的启动程序,也就是我们的程序入口 talk is cheap ,show me the code #encoding:utf-8 from app import Application,BaseRequest from httpserver import HttpServer from log import logger class MainHandler(BaseRequest): def get(self,*path_args,**path_kwargs): self.set_cookie('cookie is there') return self.Response(''' iotshineyou can see this page means the core code is running successful''') SERVER_ADDRESS = (HOST,PORT) = ('',8888) def make_server(server_address,application): server = HttpServer(server_address) server.add_app(application) return server if __name__ == '__main__': application = Application( [(r\"/\", MainHandler), (r\"/favicon.ico\", MainHandler) ]) http = make_server(SERVER_ADDRESS,application) logger.info('server serving on address :{port}..n'.format(port =str(PORT))) http.run() 我们从 if name == 'main';开始讲解这个胶水般的main.py程序入口 我们这个框架写的所有的代码都是围绕着这个main.py入口来展开的 先实例一个application类,注意到我们这里实例传入的参数是一个列表,这个列表主要对应的是我们的路由解析, 比如在这个例子中我们使用了[(r\"/\", MainHandler), (r\"/favicon.ico\", MainHandler) ]作为参数传入application类 然后再实例一个httpserver类,这个是我们的框架可以接受连接的基础.实例httpserver类后我们要把前面实例的application类也传入httpserver实例类,同时也把我们要绑定的地址和端口也以数组的形式传入httpserver类里面. 一行代码就可以运行我们的服务器了,我们可以直接调用httpserver.run() 下面我们来看下我们的运行效果图,容我开心片刻,因为我知道后面会有更多的工作要做,来,贴两张图怎么一下我的代码是可以跑的,负载测试的图我就不贴了,毕竟是一个异步高性能的服务器+框架.负载性能太低都说不过去的 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"7.来一个最简陋的orm.html":{"url":"7.来一个最简陋的orm.html","title":"实现一个最简陋的orm","keywords":"","body":"说来惭愧 以前对数据库的运用一直很不熟练,刚刚好通过自制orm这个过程可以熟悉一下嵌入式数据库操作 一开始我使用的最普通的数据库连接方式,但是后发现连接效率很低,同时也缺乏相应的连接管理机制,后来开发群里的一个前辈提醒我改用连接池来管理连接,所以就有下面的代码了 在下面的代码中我应用了DBUtils数据库连接池 包模块中的PooledDB DBUtils提供两种外部接口： PersistentDB ：提供线程专用的数据库连接，并自动管理连接。 PooledDB ：提供线程间可共享的数据库连接，并自动管理连接。 PersistentDB 和 PooledDB 都是为了重用数据库连接来提高性能，并保持数据库的稳定性。 所以选择何种模块，可以参考上面的解释。 PersistentDB 将会保持一定数量的连接供频繁使用。在这种情况下总是保持固定数量的连接。如果你的程序频繁的启动和关闭线程，最好使用 PooledDB 又到了贴代码的时刻啦!!!! #encoding=utf-8 import MySQLdb import sys from log import logger from DBUtils.PooledDB import PooledDB from config import DATABASES class Mysql(object): Mysql_Pool = None conn_num = 0 pool_num = 0 def __init__(self): Mysql.Mysql_Pool = Mysql.GetConnection() @staticmethod def GetConnection(): if Mysql.Mysql_Pool is None: Mysql.pool_num+=1 Mysql_Pool = PooledDB(creator=MySQLdb,mincached =1,maxcached =200, host = DATABASES[\"HOST\"],port = DATABASES[\"PORT\"],user = DATABASES[\"USER\"], db = DATABASES[\"NAME\"],use_unicode=False,charset=DATABASES[\"CHAR\"]) return Mysql_Pool @staticmethod def Get_conn(): if Mysql.Mysql_Pool is None: Mysql() Mysql.conn_num +=1 return Mysql.Mysql_Pool.connection() else: Mysql.conn_num +=1 return Mysql.Mysql_Pool.connection() 在上面的代码中我实现了功能类似于单例模式的mysql连接池的封装,用户只需要调用 Mysql. Get_conn()就可以获取一个连接 使用连接池后我们只管使用连接就好了,不用担心其他的问题,而且效率比普通的连接大致快了6倍左右. 下面来看看basemodel的类,在定义模型的时候理论上最好继承中国基类,这样就是可以愉快调用写好在basemodel里面的各种方法了,同样这类会比较大,毕竟有那么多的方法可以自定义,下面就简单的把关键的代码贴出来看一看解释解释一下: class BaseModel(object): \"\"\"docstring for BaseModel :这是一个model的基类,建议所有的model都继承这个类 这样就可以正大光明的使用里面 自己定义的各种sql语句的封装了\"\"\" def __init__(self,name,args={}): print 'init BaseModel',name self.table = name result = None self.index =None print self.table self.mysql_conn = Mysql.Get_conn() self.cur = self.mysql_conn.cursor() if len(args)>0: sql= self.prepare_sql('select',args) try: self.cur.execute(sql) result= self.cur.fetchone() except MySQLdb.Error,e: print \"Mysql Error %d: %s\" % (e.args[0], e.args[1]) if result!=None: self.index= result[0] print 'self.index = ',self.index def __del__(self): print 'eciting' self.cur.close() self.mysql_conn.commit() self.mysql_conn.close() def prepare_sql(self,method,args={}): avalible_method = ['insert','select','update','delete'] exe_method = None if method in avalible_method: exe_method = method else: return \"there is invalide method ,avalible_method in ['insert','select','update','delete']\" if exe_method ==\"select\": sql_str =\"select * from \"+self.table+\" where \" if len(args)>0: for key in args: if isinstance(args[key],str): sql_str+= str(key)+ \" = '\" +str(args[key])+\"' and \" else: sql_str+= str(key)+ \" = \" +str(args[key])+\" and \" return sql_str.strip(\" and \") elif exe_method == \"insert\": key= \" (\" key += \"\".join([i+\",\" for i in args]).strip(\",\") print key value=\"\" for i in args: if isinstance(args[i],str): value+=\"'\"+args[i]+\"',\" else: value+= str(args[i])+\",\" print value sql_str = \"insert into \"+self.table+key+\") values(\"+value.strip(\",\")+\")\" return sql_str elif exe_method ==\"update\": strings=\"\" for i in args: if isinstance(args[i],str): strings += \" \"+i+\"='\"+args[i]+\"',\" else: strings += \" \"+i+\"=\"+str(args[i])+\",\" if self.index==None: raise DatabaseError(\"please instance the BaseModel\") sql_str = \"update \"+self.table+\" set \"+strings.strip(\",\")+\" where id=\"+ str(self.index) return sql_str elif exe_method==\"delete\": if self.index ==None: raise DatabaseError(\"please instance the BaseModel\") sql_str = \"delete from \"+self.table+\" where id = \"+str(self.index) return sql_str def find(self,**args): sql= self.prepare_sql('select',args) print sql result = None try: self.cur.execute(sql) result= self.cur.fetchall() except MySQLdb.Error,e: print \"Mysql Error %d: %s\" % (e.args[0], e.args[1]) #print isinstance(result[1][2],unicode) print result return result 下面来简单的解释一下里面的几个核心的函数的作用 init()函数主要是用来初始化basemodel,同时向mysql类连接池申请一个连接,同时初始化一个游标, del()的方法主要是在调用类结束后自动把连接关闭,把资源空出来还给连接池. prepare_sql()主要功能是拼接sql原生语句,然后返回这个sql语句, find()这个函数就是具体的orm功能函数了,用户可调用这个方法来找到匹配的数据行.同时还有其他的get,insert,update.delete等常用的方法,就不一一解释了,当然也可以直接调用mysql类来申请一个连接,直接调用cur.execute()来直接使用原生的sql语句. 在使用的时候大致可以像下面的代码示例那样子使用,当然还有更多很灵活的用法,iotshine的orm并没有做太多的工作,只是做了点简单的封装. class device_sensor(BaseModel): def __init__(self,**args): super(device_sensor, self).__init__(self.__class__.__name__,args) print self.table if __name__ == \"__main__\": #a = device_sensor().find(sensor_name=\"Int 传感器\") #b = device_sensor().find(data_type=1) #c = device_sensor().insert(sensor_name='outshine',sensor_slug=234,is_active=1,sensor_device_id=1,data_type=1) #x.update(data_type=1,sensor_slug=233) #b.update(data_type=1,sensor_slug=233) 目前在orm是简单的不能再简单的,后面会参考先进的orm进行修改个改进,争取在好用和轻量之中做到平衡 下一篇要讲讲关于异步任务队列,异步任务队列对于我们的平台的性能是很关键的一步,如果没有异步队列,我们前面的epoll模型也是没有什么用的,毕竟数据库连接是涉及到io阻塞的,这个会极大的阻塞整个线程. 下一篇也是我在2015年最后一篇, 后面的开发和完善要等考试月结束后寒假回家安安静静的开发了 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"8.celery分布式任务队列.html":{"url":"8.celery分布式任务队列.html","title":"celery分布式任务队列","keywords":"","body":"这一篇文章来说说celery的分布式任务队列 首先,要明白这几个问题 为什么要分布式任务队列? 为什么使用celery这个分布式任务队列? 如何在项目中使用celery来执行异步任务队列? 回答第一个问题:为什么使用分布式任务队列 Celery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。 这个和我们的任务需求很相似,我们的服务器需要有哪些性能的需求呢?首先就是要可以承受高负载,这个我们前面使用高性能的nginx做负载均衡和静态文件处理,所以这方面我们不用太担心.至于我们自己写的httpserver那块 ,使用了epoll这种高效的io复用模型,也可以很轻松的解决高并发的带来的问题. 那么现在影响我们服务器性能的关键就是我们的框架业务处理部分,这部分的代码会涉及到数据库的操作还有普通的磁盘io操作,所以这里我们就可以异步的任务队列,我们把每个业务扔给任务队列,这个队列然后异步的处理队列里面的每个任务,这样不会阻塞我们的主线程,下面的图可以简单的解释一下为什么要使用分布式任务队列 其他的两个问题见下文 话不多说,马上来体验一下celery异步任务队列的魅力吧 编写应用程序 使用@app.task修饰函数就可以了 $ pip install -U Celery from celery import Celery import time app = Celery('tasks',backend='redis://127.0.0.1:6379' ,broker='redis://127.0.0.1:6379') @app.task def add(x, y): print 'success add %d%d=%d'%(x,y,x+y) time.sleep(5) return x + y 运行 Celery 任务服务器 celery -A tasks worker 来执行我的celery服务器 在生产环境中你会想要让celery程序作为守护程序在后台运行。你需要用你所在平台提供的工具来实现，或是像 supervisord 这样的东西 调用我们任务, from tasks import add add.delay(4, 4) 这是最简单的调用方式了 . 保存结果 下例中你将会使用 redis结果后端来发送状态消息。后端通过 Celery 的 backend 参数来指定。如果你选择使用配置模块，则通过 CELERY_RESULT_BACKEND 选项来设置: （常见的搭配）: app = Celery('tasks',backend='redis://127.0.0.1:6379' ,broker='redis://127.0.0.1:6379') 配置好结果后端后，让我们再次调用任务。这次你会得到调用任务后返回的 AsyncResult 实例: result = add.delay(4, 4) ready() 方法查看任务是否完成处理: result.ready() 你可以等待任务完成，但这很少使用，因为它把异步调用变成了同步调用: result.get(timeout=1) 倘若任务抛出了一个异常， get() 会重新抛出异常， 但你可以指定 propagate 参数来覆盖这一行为: result.get(propagate=False) 如果任务抛出了一个异常，你也可以获取原始的回溯信息: result.traceback 以上是参考celery的官方文档的:详情见 官方文档 上面是对celery的简单介绍,具体在项目的应用等demo应用发布了就可以直接看源代码了. 开发到这里说实话硬件负载服务器的框架的整体已经搭建差不多了,接下里的是继续完善该框架的各种功能和提高框架的性能和稳定性. 如果看了第一篇文章应该知道,我们整个系统是由两部分组成的 是硬件负载服务器 是用户控制台. 前面的这么几篇文章都是关于第一部分硬件负载服务器的,后面在开发服务器程序的同时也要开发用户控制台了 关于用户控制台,我会使用PHP或者django来开发,至于为什么要把这个系统分为两个分割的平台是有原因的 一方面是提高了系统的容错性 另外一方面硬件服务器可能需要实现各种自定义的协议,直接用其他的异步框架(如tornado)会极大限制了灵活性. 把用户控制台分离便于不断的迭代更新,一个系统变得庞大时就得考虑模块分离了,而我们的iotshine一开始就将这两大模块分离出来.虽然配置起来可能不是很方便,可是谁叫人生在于折腾呢 Copyright © 2019 outshineamaze.All rights reserved. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"}}